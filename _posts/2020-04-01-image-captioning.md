---
title: Image Captioning System
description: The blog is going to build a web system that can automatically generate natural language description for the image. In the whole system, the core component is building an image captioning model to process the image.
categories:
 - NLP
 - CV
 - DL
tags:
---

## Introduction
About image captioning, there are three well-studied approaches to automatic image captioning: retrieval based image captioning, template based image cap-
tioning, and deep neural network based image captioning[2]. Moreover, each approach can be divided into some subcategories based on the specific method
and framework. In terms of the retrieval based model, Hodosh et al.[3] establish a framework for sentence-based image description by ranking a given pool of captions. Or-
donez et al.[4] used 1 Million Captioned Photographs associated with human-
generated description to develop an automatic image description method by
filtering and retrieving. The advantage of retrieval-based methods is that al-
ways return well-formed human-written captions, but in some conditions, these
captions may not be able to describe the image properly.
Another method is called the template based model, generating caption
through a syntactically and semantically constrained process. Yang et al.[5]
first extracted nouns, verbs, scenes, and prepositions from the image then used
these to generate the sentence by the statistical language model. Li et al.[6]
used a similar method, the whole process can be divided into two steps, phrase
selection and phrase fusion. Compared with the retrieval based model, the cap-
tion generated by this approach is more relevant, but the sentence is usually
simple and less creative.
Besides, with the development of the neural network, some generation method
like seq-2-seq model has been used to solve this problem, motivated by the
neural machine translation. Kiros et al. [7] brought the encoder-decoder frame-
work into image captioning area by unifying joint image-text embedding models
through multimodal neural language models. Vinyals et al.[8] used to CNN as
encoder and LSTM as decoder for image captioning, by the pre-trained image
representation and treating the last hidden layer as input to the decoder. Fang
et al.[9] presents a compositional approach combining visual detectors, language
models, and multimodal similarity models for automatically generating image
descriptions, learning directly from a dataset of image captions. You et al.[10]
proposes a new image captioning approach that combines the top-down and
bottom-up approaches through a semantic attention model.
Since deep learning structure is the black box and we cannot understand
and control its processing, Marcella et al.[11] proposes a novel image captioning
method which can generate diverse descriptions by allowing both grounding and
controllability. Moreover, if people want to get a paragraph that contains more
than one sentence, the above methods cannot generate diverse sentences, which
meaning generating repeated sentences. Hence, Luck et al.[12] raises a method
that can generate sentences with diversity and can combine these sentences into
a whole paragraph organically.
2Automatic image captioning is a relatively new task, the network with en-
coder and decoder is widely used in this area, currently. Besides, some im-
provement tricks like attention mechanisms used in other areas like machine
translation can also apply in image captioning.


## System Architecture(Online & Offline)
About the architecture of recommender systems, it is a difficult problem in industry. There are two main components called recall layer and ranking layer.





# References
https://static.googleusercontent.com/media/research.google.com/ru//pubs/archive/45530.pdf
https://zhuanlan.zhihu.com/p/58160982
https://zhuanlan.zhihu.com/p/100019681
https://juejin.im/post/5c8a0c205188257ded10e4a0

