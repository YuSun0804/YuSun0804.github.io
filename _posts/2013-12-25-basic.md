---
title: Block
date: 2013-12-25 00:14:39
cegories:
- Foo
tags:
---

# RPC
1. RPC协议：
服务调用：服务调用、参数传递、路由、负载均衡
- p客户端是如何完成远程调用的？调用方式有哪些？
- P是如何完成远程调用参数传递的？
- P客户端是如何完成请求到服务端的路由的？
- P是通过什么方式做负载均衡的？P提供哪些策略？这些策略如何选择？

2. 服务性能 I/O模型、线程模型、序列化机制
- P是如何满足性能需求的？高性能rpc的核心问题是什么？
- I/O模型、线程模型、序列化机制与P的关系是什么？
- 什么是协议？P网络层通信协议是共有协议还是私有协议？
  https://github.com/baidu/Jprotobuf-rpc-socket/wiki/RPC%E9%80%9A%E8%AE%AF%E5%8D%8F%E8%AE%AE%E8%A7%84%E8%8C%83
  包头（长度，序列化标记，压缩标记） 消息头 消息体 校验码
- P底层的I/O模型是怎么样的？P和netty是什么关系？
- P底层的线程模型是怎么样的？
- P提供哪些序列化方式？序列化方式有哪些指标？性能与压缩比如何权衡？

3. 服务容错 服务超时、异常处理机制
- P调用如果失败（异常等）P提供了哪些处理机制

4. 服务发现 服务注册、发现与注销
- P是如何实现服务注册与服务发现的？
- 目前的服务注册于服务发现机制有什么隐藏的问题？
- P和zookeeper的关系是什么？
- P是如何实现服务注销的？

5. 服务监控 链路监控、性能监控、其他监控
- P实现了哪些维度的监控？
- 分别针对了哪些指标进行监控？
- 监控对于P的意义是什么？

6. 服务可用性 隔离、降级、限流
- P是如何保证服务的可用性的？
- P是如何实现服务隔离的？为什么要隔离？
- P是如何实现服务降级的？降级策略有哪些？为什么要服务降级？
- P是如何实现限流的？限流解决什么问题？限流方式与策略有哪些？
- P是如何实现服务容错的？
- 针对可应用问题P还有哪些方面可以改进的？

7. 服务治理 服务治理
- 服务治理包括哪些内容？
- P实现了哪些服务治理功能？


# c监控
1. 数据获取
- c能监控的数据范围，例如：网络监控，app监控，服务器监控等，每种监控数据的获取方式

2. 数据上报
- c的数据传输方式，例如：使用什么协议传输，大数据是否会进行分片等
- c是通过什么方式来描述监控的数据的
通常java客户端在业务上使用容易出问题的地方就是内存，另外一个cpu，内存往往是内存泄露，占用内存较多导致业务方gc压力增大。客户端的代码性能决定了最终CPU的消耗。
- 采样

以前我们遇到过一个极端的例子，我们一个业务请求做餐饮加商铺的销售额，业务一般会通过for循环所有商铺的分店，结果就造成内存OOM了，后来发现这家店是肯德基，有几万分店，每个循环里面都会有数据库连接。在正常场景下，ThreadLocal内部的监控一个对象就存在几万个节点，导致业务Oldgc特别严重。所以说框架的代码是不能想象业务方会怎么用你的代码，需要考虑到任何情况下都可能有出问题的可能。

在消耗CPU方面我们也遇到一个case，在某个客户端版本，c本地存储当前消息ID自增的大小，客户端使用了MappedByteBuffer这个类，这个类是一个文件内存映射，测试下来这个类的性能非常高，我们仅仅用这个存储了几个字节的对象，正常情况理论上不会有任何问题。在一次线上一个场景下，很多业务线程都block在这个上面。当系统IO存在瓶颈时候，MappedByteBuffer这个类使用也会变得很慢。后来的优化就是把这个io的操作异步化，所以客户端需要尽可能异步化，异步化序列化，异步化传输，异步化任何可能存在时间延迟的代码操作。

3. 实时计算
- 针对那么高的数据量，是通过什么方式实时计算的

c服务端在整个实时处理中，基本上实现了全异步化处理。
消息接收是基于Netty的NIO实现。
消息接收到服务端就存放内存队列，然后程序开启一个线程会消费这个消息做消息分发。
每个消息都会有一批线程并发消费各自队列的数据，以做到消息处理的隔离。
消息存储是先存入本地磁盘，然后异步上传到hdfs文件，这也避免了强依赖hdfs。
当某个报表处理器处理来不及时候，比如Transaction报表处理比较慢，可以通过配置支持开启多个Transaction处理线程，并发消费消息。

c基本上所有的报表模型都可以增量计算，它可以分为：计数、计时和关系处理三种。计数又可以分为两类：算术计数和集合计数。典型的算术计数如：总个数（count），总和（sum），均值（avg），最大/最小（max/min)，吞吐（tps）和标准差（std）等，其他都比较直观，标准差稍微复杂一点，大家自己可以推演一下怎么做增量计算。那集合运算，比如95线（表示95%请求的完成时间），999线（表示99.9%请求的完成时间），则稍微复杂一些，系统开销也更大一点。

c服务端为每个报表单独分配一个线程，所以不会有锁的问题，所有报表模型都是非线程安全的，其数据是可变的。这样带来的好处是简单且低开销。

4. 数据存储
- c对于监控数据的存储方式，例如：不同数据是怎么存储的，有没有进行数据压缩等
c将所有的报表按消息的创建时间，一小时为单位分片，那么每小时就产生一个报表。当前小时报表的所有计算都是基于内存的，用户每次请求即时报表得到的都是最新的实时结果。对于历史报表，因为它是不变的，所以就实时不实时也就无所谓了。

c系统的存储主要有两块

c的报表的存储
c原始logview的存储。
报表是根据logview实时运算出来的给业务分析用的报表，默认报表有小时模式，天模式，周模式以及月模式。c实时处理报表都是产生小时级别统计，小时级报表中会带有最低分钟级别粒度的统计。天、周、月等报表都是在小时级别报表合并的结果报表。

原始logview存储一天大约200TB的数据量，因为数据量比较大所以存储必须要要压缩，原始logview需要根据messageId读取。在这样的情况下，存储整体要求就是批量压缩以及随机读。在当时场景下，并没有特别合适成熟的系统以支持这样的特性，所以我们开发了一种基于文件的存储以支持c的场景，在存储上一直是最难的问题，我们一直在这块持续的改进和优化。

消息ID的设计
c每个消息都有一个唯一的ID，这个ID在客户端生成，后续c都通过这个ID在进行消息内容的查找。比如在分布式调用里面，RPC消息需要串起来，比如A调用B的时候，在A这端生成一个MessageId，在A调用B的过程中，将MessageId作为调用传递到B端，在B执行过程中，B用context传递的MessageId作为当前监控消息的MessageId。

c消息的MessageId格式ShopWeb-0a010680-375030-2，c消息一共分为四段

第一段是应用名shop-web。
第二段是当前这台机器的ip的16进制格式，01010680表示10.1.6.108。
第三段的375030，是系统当前时间除以小时得到的整点数。
第四段的2，是表示当前这个客户端在当前小时的顺序递增号。

消息存储是c最有挑战的部分。关键问题是消息数量多且大，目前美团点评每天处理消息2000亿左右，大小大约200TB，单物理机高峰期每秒要处理100MB左右的流量。c服务端基于此流量做实时计算，还需要将这些数据压缩后写入磁盘。

c数据文件分为两种，一类是index文件，一类是Data文件

data文件是分段GZIP压缩，每个分段大小小于64K，这样可以用16bits可以表示一个最大分段地址。
一个MessageId都用需要48bits的空间大小来存索引，索引根据MessageId的第四段来确定索引的位置，比如消息MessageId为ShopWeb-0a010680-375030-2，这条消息ID对应的索引位置为2*48bits的位置。
48bits前面32bits存数据文件的块偏移地址，后面16bits存数据文件解压之后的块内地址偏移。
c读取消息的时候，首先根据MessageId的前面三段确定唯一的索引文件，在根据MessageId第四段确定此MessageId索引位置，根据索引文件的48bits读取数据文件的内容，然后将数据文件进行GZIP解压，在根据块内偏移地址读取出真正的消息内容，


c在分布式实时方面，主要归结于以下几点因素：

去中心化，数据分区处理。
基于日志只读特性，以一个小时为时间窗口，实时报表基于内存建模和分析，历史报表通过聚合完成。
基于内存队列，全面异步化，单线程化，无锁设计。
全局消息ID，数据本地化生产，集中式存储。
组件化、服务化理念。

# Netty
1. 线程模型
https://www.jianshu.com/p/38b56531565d

# JAVA基础
1. JVM 
- 垃圾回收的算法与实现
2. NIO
3. 线程池
其中比较容易让人误解的是：corePoolSize，maximumPoolSize，workQueue之间关系。 
1.当线程池小于corePoolSize时，新提交任务将创建一个新线程执行任务，即使此时线程池中存在空闲线程。 
2.当线程池达到corePoolSize时，新提交任务将被放入workQueue中，等待线程池中任务调度执行 
3.当workQueue已满，且maximumPoolSize>corePoolSize时，新提交任务会创建新线程执行任务 
4.当提交任务数超过maximumPoolSize时，新提交任务由RejectedExecutionHandler处理 
5.当线程池中超过corePoolSize线程，空闲时间达到keepAliveTime时，关闭空闲线程 
6.当设置allowCoreThreadTimeOut(true)时，线程池中corePoolSize线程空闲时间达到keepAliveTime也将关闭 

# Redis
1. 异地双中心
2. 故障恢复
3. 主从同步
4. 淘汰机制

# Kafka
# ZooKeeper
# Mysql
http://www.10tiao.com/html/249/201902/2651961957/1.html 
1. 索引类型
从数据结构角度
1、B+树索引(O(log(n)))：关于B+树索引，http://blog.codinglabs.org/articles/theory-of-mysql-index.html
https://www.cnblogs.com/boothsun/p/8970952.html
Innodb中B+树 数据页节点存放的是完整的每行记录；非数据页节点存放仅仅是键值和指向数据页的指针

2、hash索引：
    a 仅仅能满足"=","IN"和"<=>"查询，不能使用范围查询
    b 其检索效率非常高，索引的检索可以一次定位，不像B-Tree 索引需要从根节点到枝节点，最后才能访问到页节点这样多次的IO访问，所以 Hash 索引的查询效率要远高于 B-Tree 索引
    c 只有Memory存储引擎显示支持hash索引
3、FULLTEXT索引（现在MyISAM和InnoDB引擎都支持了）
4、R-Tree索引（用于对GIS数据类型创建SPATIAL索引）

从物理存储角度
1、聚集索引（clustered index）
2、非聚集索引（non-clustered index）

从逻辑角度
1、主键索引：主键索引是一种特殊的唯一索引，不允许有空值
2、普通索引或者单列索引
3、多列索引（复合索引）：复合索引指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用复合索引时遵循最左前缀集合
4、唯一索引或者非唯一索引
5、空间索引：空间索引是对空间数据类型的字段建立的索引，MYSQL中的空间数据类型有4种，分别是GEOMETRY、POINT、LINESTRING、POLYGON。

2. 事务隔离性
另外一篇文章：
事务回滚等机制实现原理

3. 锁机制
- MyIsam表级锁，不支持事务。读数据上 读锁，写数据上 写锁，只有读读 不互斥，读写、写写均互斥；不会发生死锁。
- Innodb行级锁，支持事务。读不加锁（快照读），写加写锁。共享/排它锁的潜在问题是，不能充分的并行，解决思路是数据多版本。
意向锁分为：意向锁是指，未来的某个时刻，事务可能要加共享/排它锁了，先提前声明一个意向。https://juejin.im/post/5b85124f5188253010326360
意向共享锁(intention shared lock, IS)，它预示着，事务有意向对表中的某些行加共享S锁
意向排它锁(intention exclusive lock, IX)，它预示着，事务有意向对表中的某些行加排它X锁
行锁是针对索引加的锁，不是针对记录加的锁。并且该索引不能失效，否则都会从行锁升级为表锁。意向锁是表级锁，意向锁不会和行锁冲突
间隙锁 https://blog.csdn.net/aaa821/article/details/81017704 https://zhuanlan.zhihu.com/p/48269420
非主索引，增加、删除不仅有记录锁，还会有间隙锁，还会对主键索引加记录锁；唯一索引范围查询也会加间隙锁；唯一索引等值查询不会加间隙锁，RC级别也不加间隙锁。
插入意向锁 一种特殊的间隙锁 提高插入的并发度
https://juejin.im/post/5b865859e51d4538e331ae9a
自增锁 自增锁是一种特殊的表级别锁（table-level lock），专门针对事务插入 AUTO_INCREMENT 类型的列。最简单的情况，如果一个事务正在往表中插入记录，所有其他事务的插入必须等待，以便第一个事务插入的行，是连续的主键值。https://www.zhihu.com/question/52119372

常见SQL语句加锁分析
https://www.aneasystone.com/archives/2017/12/solving-dead-locks-three.html
delete不同情况下加的锁，update语句类似
http://www.fordba.com/lock-analyse-of-delete.html
锁日志
https://cloud.tencent.com/developer/article/1181190



4. 主从复制

5. 数据库查询
避免在WHERE子句中使用in，not in，or 或者having
可以使用 exist 和not exist代替 in和not in
可以使用表链接代替 exist
Having可以用where代替

子查询和表 join
https://blog.csdn.net/joenqc/article/details/73332402

SELECT EMPLOYEE_ID,FIRST_NAME,DEPARTMENT_ID,SALARY FROM EMPLOYEES e1 WHERE ( SALARY > (SELECT AVG(SALARY) FROM EMPLOYEES e2 WHERE  e1.department_id = e2.department_id))；
上述语句的执行过程为：
1.select * from employees;  得到查询结果集g1
2.利用g1的每条记录，执行子查询select avg(salary) from employees where g1.department_id = department_id;得到临时结果avg_salary
3.where 语句判定 g1.salary > avg_salary 
4.循环2，3步，直到g1查询完
分析上面的查询过程，可以看出对同一个department_id用了多次的子查询，可以采用临时表的方式优化，SQL语句为

SELECT employee_id,first_name,salary from employees t1,(select department_id,avg(salary) as avg from employees group by department_id) t2 where t1.department_id = t2.department_id and t1.salary > t2.avg;

用mysql workbench 看执行结果

表join
https://www.cnblogs.com/JohnABC/p/7150921.html

Order by 原理（B+树有序，可以利用索引直接排序）
https://blog.csdn.net/hguisu/article/details/7161981

Group by 原理
https://blog.csdn.net/weixin_39666581/article/details/82229183

distinct 原理
https://www.cnblogs.com/ggjucheng/archive/2012/11/18/2776449.html

count
https://my.oschina.net/lyaohe/blog/831174
类似sum的函数还有min(),max(),这些都需要在字段上建索引。聚合函数avg，优化思路和sum基本类似，而max和min则处理有些区变化，max和min都是可能直接通过索引min max扫描（直接扫描索引的头部或者尾部）来完成查询的

索引失效
https://www.jianshu.com/p/9c9a0057221f

但是如果使用Select、Insert、Update替换方案，但是可能有以下问题：
如果使用的是当前读的Select for update
Select for update在数据库里面不包含条件的数据时会产生Gap锁，和Insert操作时互斥的，并发情况下可能会导致死锁
Select for update是悲观锁，性能很难保证
如果使用的是快照读的Select
直接使用Select，数据库不会加锁，不能保证查到的数据是最新数据，同时Insert操作会发生而产生duplicate key error
可以考虑以下替代方案：
改成读缓存、Update、Insert、失败重试的方式来执行。
通过Insert预生成数据，之后所有的请求都是Update操作。这种方案的性能会比较好，但是这种方案改造的成本可能会比较大，在此不做讨论。




简书闪电侠
大规模分布式存储系统
性能之巅